{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNczVyO2yFOQDmlXOdx1ztQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nw93929/DS2002FinalProject/blob/main/SCRIPTS/etl_pipeline_setup_implementation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf DS2002FinalProject\n",
        "!git clone https://github.com/nw93929/DS2002FinalProject.git\n",
        "%cd DS2002FinalProject"
      ],
      "metadata": {
        "id": "3uyH1gAiojPo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f91637d6-19f3-4dfa-8958-68d145a9ff39"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'DS2002FinalProject'...\n",
            "remote: Enumerating objects: 112, done.\u001b[K\n",
            "remote: Counting objects: 100% (112/112), done.\u001b[K\n",
            "remote: Compressing objects: 100% (61/61), done.\u001b[K\n",
            "remote: Total 112 (delta 45), reused 112 (delta 45), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (112/112), 16.63 MiB | 17.92 MiB/s, done.\n",
            "Resolving deltas: 100% (45/45), done.\n",
            "/content/DS2002FinalProject\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "kx1YECgnb2Ca",
        "outputId": "86afc86c-8f24-402f-c767-dd1cb2391095"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n",
            "Requirement already satisfied: openpyxl in /usr/local/lib/python3.10/dist-packages (3.1.5)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.10/dist-packages (2.0.36)\n",
            "Collecting pymysql\n",
            "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.10/dist-packages (2.8.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.10/dist-packages (from openpyxl) (2.0.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (4.12.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy) (3.1.1)\n",
            "Requirement already satisfied: google-auth<3.0dev,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.27.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.19.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.4.1)\n",
            "Requirement already satisfied: google-resumable-media>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.7.2)\n",
            "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-cloud-storage) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.66.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0.dev0,>=3.19.5 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (4.25.5)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0dev,>=1.31.5->google-cloud-storage) (1.25.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0dev,>=1.25.0->google-cloud-storage) (4.9)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.10/dist-packages (from google-resumable-media>=2.3.2->google-cloud-storage) (1.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0dev,>=2.18.0->google-cloud-storage) (2024.8.30)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0dev,>=1.25.0->google-cloud-storage) (0.6.1)\n",
            "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymysql\n",
            "Successfully installed pymysql-1.1.1\n"
          ]
        }
      ],
      "source": [
        "# Need to install necessary libraries\n",
        "!pip install pandas openpyxl sqlalchemy pymysql google-cloud-storage"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def run_pipeline():\n",
        "    import pandas as pd\n",
        "\n",
        "    # Load necessary data\n",
        "    outcomes = pd.read_excel('Data/WinningPartyByCounties.xlsx')\n",
        "    demographics2012 = pd.read_excel('Data/demographicsswingstates2012.xlsx')\n",
        "    demographics2016 = pd.read_excel('Data/demographicsswingstates2016.xlsx')\n",
        "    demographics2020 = pd.read_excel('Data/demographicswingstates2020.xlsx')\n",
        "\n",
        "    # Clean outcomes data\n",
        "    outcomes['state'] = outcomes['state'].str.capitalize()\n",
        "    outcomes['county_name'] = outcomes['county_name'].str.capitalize()\n",
        "    columns_to_drop = ['office', 'version', 'county_fips', 'mode']\n",
        "    outcomes_cleaned = outcomes.drop(columns=columns_to_drop)\n",
        "\n",
        "    # Columns to keep\n",
        "    columns_to_keep = [\n",
        "        'County Name', 'State Name', 'Males 18-24 %', 'Females 65+ %',\n",
        "        'White alone %', 'Black or African American alone %',\n",
        "        'less than $39,999 %', 'more than $200,000 %',\n",
        "        'Regular high school diploma %', \"Master's degree %\",\n",
        "        'In labor force %', 'Not in labor force %'\n",
        "    ]\n",
        "    columns_to_keep_2016 = [\n",
        "        'County Name', 'State Name', 'Males 18-24 %', 'Females 65+ %',\n",
        "        'White alone %', 'Black or African American alone %',\n",
        "        'less than $39,999 %', 'more than $200,000 %',\n",
        "        'Regular high school diploma %', \"Master's degree %\",\n",
        "        'In labor force Percentage %', 'Not in labor force Percentage %'\n",
        "    ]\n",
        "\n",
        "    # Clean demographics data\n",
        "    demographics2012_cleaned = demographics2012[columns_to_keep]\n",
        "    demographics2016_cleaned = demographics2016[columns_to_keep_2016].rename(\n",
        "        columns={\n",
        "            \"In labor force Percentage %\": \"In labor force %\",\n",
        "            \"Not in labor force Percentage %\": \"Not in labor force %\"\n",
        "        }\n",
        "    )\n",
        "    demographics2020_cleaned = demographics2020[columns_to_keep]\n",
        "\n",
        "    # Add 'year' column\n",
        "    demographics2012_cleaned['year'] = 2012\n",
        "    demographics2016_cleaned['year'] = 2016\n",
        "    demographics2020_cleaned['year'] = 2020\n",
        "\n",
        "    # Standardize column names for merging\n",
        "    for df in [demographics2012_cleaned, demographics2016_cleaned, demographics2020_cleaned]:\n",
        "        df['county_name'] = df['County Name'].str.replace(r'\\s*County\\s*$', '', regex=True).str.strip().str.title()\n",
        "        df['state'] = df['State Name'].str.strip().str.title()\n",
        "\n",
        "    # Merge datasets\n",
        "    merged_2012 = pd.merge(\n",
        "        outcomes_cleaned[outcomes_cleaned['year'] == 2012],\n",
        "        demographics2012_cleaned,\n",
        "        on=['county_name', 'state'],\n",
        "        how='inner'\n",
        "    )\n",
        "    merged_2016 = pd.merge(\n",
        "        outcomes_cleaned[outcomes_cleaned['year'] == 2016],\n",
        "        demographics2016_cleaned,\n",
        "        on=['county_name', 'state'],\n",
        "        how='inner'\n",
        "    )\n",
        "    merged_2020 = pd.merge(\n",
        "        outcomes_cleaned[outcomes_cleaned['year'] == 2020],\n",
        "        demographics2020_cleaned,\n",
        "        on=['county_name', 'state'],\n",
        "        how='inner'\n",
        "    )\n",
        "\n",
        "    # Combine all years\n",
        "    merged_data = pd.concat([merged_2012, merged_2016, merged_2020], axis=0)\n",
        "\n",
        "    # Clean up column names\n",
        "    if 'year_y' in merged_data.columns:\n",
        "        merged_data = merged_data.drop(columns=['year_y'])\n",
        "    if 'year_x' in merged_data.columns:\n",
        "        merged_data = merged_data.rename(columns={'year_x': 'year'})\n",
        "\n",
        "    # Return final dataset\n",
        "    return merged_data"
      ],
      "metadata": {
        "id": "231DkBh_nZth"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sqlalchemy import create_engine, text\n",
        "\n",
        "# Database connection details\n",
        "db_username = 'root'\n",
        "db_password = 'election-project-data'\n",
        "public_ip = '35.199.15.59'\n",
        "db_name = 'outcomes-demographics'\n",
        "\n",
        "# Create a database engine\n",
        "engine = create_engine(f'mysql+pymysql://{db_username}:{db_password}@{public_ip}/{db_name}')\n",
        "\n",
        "# Define a table creation query\n",
        "create_table_query = \"\"\"\n",
        "CREATE TABLE outcomes_demographics (\n",
        "    id INT AUTO_INCREMENT PRIMARY KEY,\n",
        "    year INT,\n",
        "    state VARCHAR(255),\n",
        "    state_po VARCHAR(255),\n",
        "    county_name VARCHAR(255),\n",
        "    candidate VARCHAR(255),\n",
        "    party VARCHAR(255),\n",
        "    candidatevotes INT,\n",
        "    totalvotes INT,\n",
        "    state_name VARCHAR(255),\n",
        "    males_18_24 FLOAT,\n",
        "    females_65_plus FLOAT,\n",
        "    white_alone FLOAT,\n",
        "    black_or_african_american_alone FLOAT,\n",
        "    less_than_39999 FLOAT,\n",
        "    more_than_200000 FLOAT,\n",
        "    regular_high_school_diploma FLOAT,\n",
        "    masters_degree FLOAT,\n",
        "    in_labor_force FLOAT,\n",
        "    not_in_labor_force FLOAT\n",
        ");\n",
        "\"\"\"\n",
        "\n",
        "# Execute the query to create the table\n",
        "try:\n",
        "    with engine.connect() as conn:\n",
        "        conn.execute(text(create_table_query))\n",
        "        print(\"Table 'outcomes_demographics' created or already exists.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating table: {e}\")\n",
        "\n",
        "# Load the CSV data\n",
        "merged_data = pd.read_csv('merged_data.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01jyj8mtE_ke",
        "outputId": "a41f1703-0cea-4e94-9dd8-cbbed674d0af"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error creating table: (pymysql.err.OperationalError) (2003, \"Can't connect to MySQL server on '35.199.15.59' (timed out)\")\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Upload the data to the MySQL table\n",
        "try:\n",
        "    merged_data.to_sql('outcomes_demographics', con=engine, if_exists='replace', index=False)\n",
        "    print(\"Data uploaded successfully to 'outcomes_demographics'.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error uploading data: {e}\")\n",
        "\n",
        "# Connecting to MySQL database to validate outcomes_demographics table upload\n",
        "try:\n",
        "    with engine.connect() as conn:\n",
        "        result = conn.execute(text(\"SELECT COUNT(*) FROM outcomes_demographics;\"))\n",
        "        row_count = result.fetchone()[0]\n",
        "        # column_count = len(result.keys())\n",
        "        print(f\"Number of rows in 'outcomes_demographics': {row_count}\")\n",
        "        # print(f\"Number of columns in 'outcomes_demographics': {column_count}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error verifying data: {e}\")"
      ],
      "metadata": {
        "id": "hAhWIi61pO5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0eecec-3c65-43e9-c670-569d71b40204"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error uploading data: (pymysql.err.OperationalError) (2003, \"Can't connect to MySQL server on '35.199.15.59' (timed out)\")\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
            "Error verifying data: (pymysql.err.OperationalError) (2003, \"Can't connect to MySQL server on '35.199.15.59' (timed out)\")\n",
            "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Validating Google Cloud bucket and connection\n",
        "import os\n",
        "from google.cloud import storage\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/ds-final-project-443519-b7e05f36c0a4.json'\n",
        "\n",
        "# Initialize the client\n",
        "client = storage.Client()\n",
        "\n",
        "# List buckets\n",
        "buckets = list(client.list_buckets())\n",
        "print(\"Buckets in the project:\")\n",
        "for bucket in buckets:\n",
        "    print(bucket.name)"
      ],
      "metadata": {
        "id": "CisKpRU2pIuC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e4ea080-1db3-4116-e5fd-a83f8a490f34"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Buckets in the project:\n",
            "ds-final-project\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# uploading merged_data.csv to google cloud bucket\n",
        "def upload_to_gcs(bucket_name, source_file_name, destination_blob_name):\n",
        "    client = storage.Client()\n",
        "    bucket = client.bucket(bucket_name)\n",
        "    blob = bucket.blob(destination_blob_name)\n",
        "    blob.upload_from_filename(source_file_name)\n",
        "    print(f\"File {source_file_name} uploaded to {destination_blob_name}.\")\n",
        "\n",
        "upload_to_gcs('ds-final-project', 'merged_data.csv', 'gs://ds-final-project/')"
      ],
      "metadata": {
        "id": "OJw9NnTMFM4D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476ecb41-2d80-4e3a-9baf-9b0a9f637552"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File merged_data.csv uploaded to gs://ds-final-project/.\n"
          ]
        }
      ]
    }
  ]
}